{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09316bd-3abd-4dcf-bb7b-fd5bba663f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark #only run after findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0999a145-99dc-4c27-bdfe-522af6da1ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.functions import array_to_vector\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, input_file_name, col\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"Imports done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e781438-45fb-4623-899e-ebda1d705035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Start!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"chest-xray-bigdata\")\n",
    "        .config(\"spark.python.worker.faulthandler.enabled\", \"true\")\n",
    "        .config(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\")\n",
    "        .config(\"spark.driver.memory\", \"8g\")\n",
    "        .config(\"spark.sql.debug.maxToStringFields\", \"10000\")\n",
    "        .config(\"spark.driver.maxResultSize\", \"2g\")\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"512m\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark Session Start!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38383fbe-06b6-47db-b6ab-dcce5f692858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing; 1000 images\n",
    "#image_dir = \"../data/images_001/training/*.png\"\n",
    "# Real use; 4999 images\n",
    "image_dir = \"../data/images_001/images/*.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3412986-7c82-46b2-844a-11e697e0ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame by loading files in \"image\" format. \"read\" creates the DataFrame\n",
    "xray_df = spark.read.format(\"binaryFile\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.png\") \\\n",
    "    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "    .load(image_dir)\n",
    "# Print the structure/schema of the DataFrame.\n",
    "xray_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0d8370-523f-41f3-96a3-45d6f2bcba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------------+\n",
      "|                path|   modificationTime|length|             content|            filename|\n",
      "+--------------------+-------------------+------+--------------------+--------------------+\n",
      "|file:/C:/Users/Bu...|2017-08-01 13:35:36|726419|[89 50 4E 47 0D 0...|file:///C:/Users/...|\n",
      "|file:/C:/Users/Bu...|2017-08-01 13:40:34|699102|[89 50 4E 47 0D 0...|file:///C:/Users/...|\n",
      "+--------------------+-------------------+------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add filenames (for assignment)\n",
    "xray_df = xray_df.withColumn(\"filename\", input_file_name())\n",
    "xray_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73adebf5-83bb-4b19-9d5b-b5e91b29bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------------------+--------------------+\n",
      "|                path|   modificationTime|length|             content|            filename|            features|\n",
      "+--------------------+-------------------+------+--------------------+--------------------+--------------------+\n",
      "|file:/C:/Users/Bu...|2017-08-01 13:35:36|726419|[89 50 4E 47 0D 0...|file:///C:/Users/...|[0.5882353, 0.623...|\n",
      "|file:/C:/Users/Bu...|2017-08-01 13:40:34|699102|[89 50 4E 47 0D 0...|file:///C:/Users/...|[0.08627451, 0.08...|\n",
      "|file:/C:/Users/Bu...|2017-07-19 09:17:10|693527|[89 50 4E 47 0D 0...|file:///C:/Users/...|[0.38039216, 0.26...|\n",
      "|file:/C:/Users/Bu...|2017-08-01 13:38:04|690140|[89 50 4E 47 0D 0...|file:///C:/Users/...|[0.28235295, 0.21...|\n",
      "|file:/C:/Users/Bu...|2017-07-19 09:27:12|687283|[89 50 4E 47 0D 0...|file:///C:/Users/...|[0.09411765, 0.08...|\n",
      "+--------------------+-------------------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define UDF using Pillow (PIL)\n",
    "@udf(returnType=ArrayType(FloatType()))\n",
    "def extract_features_pil(file_content):\n",
    "    if file_content is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # 1. Open Image from Bytes\n",
    "        image = Image.open(io.BytesIO(file_content))\n",
    "        \n",
    "        # 2. Convert to Grayscale ('L') to match channels=1\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        # 3. Resize to 256x256\n",
    "        image = image.resize((256, 256))\n",
    "        \n",
    "        # 4. Convert to Numpy Array & Normalize\n",
    "        img_array = np.array(image).astype(np.float32) / 255.0\n",
    "        \n",
    "        # 5. Flatten to list\n",
    "        return img_array.flatten().tolist()\n",
    "        \n",
    "    except Exception as e:\n",
    "        # This catch block will actually work now for Pillow errors\n",
    "        return None\n",
    "\n",
    "# Apply the stable UDF\n",
    "xray_feature_df = xray_df.withColumn(\"features\", extract_features_pil(col(\"content\")))\n",
    "\n",
    "# Filter out failures\n",
    "clean_xray_df = xray_feature_df.filter(col(\"features\").isNotNull())\n",
    "\n",
    "# Test - This should finally work\n",
    "clean_xray_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e421a57f-85b3-4cff-a687-7208a48ac74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            filename|            features|\n",
      "+--------------------+--------------------+\n",
      "|file:///C:/Users/...|[0.58823531866073...|\n",
      "|file:///C:/Users/...|[0.08627451211214...|\n",
      "|file:///C:/Users/...|[0.38039216399192...|\n",
      "|file:///C:/Users/...|[0.28235295414924...|\n",
      "|file:///C:/Users/...|[0.09411764889955...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Array<Float> to DenseVector. Carry over the filenames.\n",
    "final_df = clean_xray_df.select(\n",
    "    col(\"filename\"),\n",
    "    array_to_vector(col(\"features\")).alias(\"features\")\n",
    ")\n",
    "\n",
    "final_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a9e012-0706-404e-8d9b-d4aebf283115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run KMeans\n",
    "kmeans = KMeans(k=15, seed=42, featuresCol=\"features\")\n",
    "model = kmeans.fit(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d788cc9-7cc6-41e0-bff6-7dfe3fa14281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate to which cluster the vectors belong\n",
    "xray_clustered_df = model.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c38664-c272-4a2b-8f6d-2afca81f5287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|  276|\n",
      "|        13|  374|\n",
      "|         5|  449|\n",
      "|         8|  375|\n",
      "|         7|  324|\n",
      "|        14|  308|\n",
      "|        12|  445|\n",
      "|         3|  300|\n",
      "|        11|  407|\n",
      "|         2|  358|\n",
      "|         9|  325|\n",
      "|         4|  299|\n",
      "|         0|  266|\n",
      "|        10|  128|\n",
      "|         6|  365|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show how many images belong to each cluster\n",
    "xray_clustered_df.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c1f812-0974-4a14-8760-b16a9c2d4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../docs/cluster_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34f132a-b196-4cb8-8840-9db9cf9c07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete old cluster outputs\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a40091-656d-42ab-91a0-92808608da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 20 filenames for each cluster\n",
    "for c in range(15):\n",
    "    output_path = f\"{output_dir}/cluster_{c}\"\n",
    "    (\n",
    "        xray_clustered_df\n",
    "        .filter(col(\"prediction\") == c)\n",
    "        .select(\"filename\")\n",
    "        .limit(20)\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .text(output_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a0f63b-5e64-4c25-97aa-faa2ed632904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing; 100 images\n",
    "#new_image_dir = \"../data/images_001/test/*.png\"\n",
    "# Real use; 10000 images\n",
    "new_image_dir = \"../data/images_002/images/*.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7e5394e-02c0-40e7-b1b6-90f5e46aca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame\n",
    "new_df = spark.read.format(\"binaryFile\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.png\") \\\n",
    "    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "    .load(new_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dca75b3-9003-4f43-9049-75161e6d012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction like during training\n",
    "new_features = new_df.withColumn(\n",
    "    \"features\",\n",
    "    extract_features_pil(col(\"content\"))\n",
    ").select(array_to_vector(col(\"features\")).alias(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8886d45-b811-41cb-b197-d81ebac5d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.21960784494876...|         5|\n",
      "|[0.16470588743686...|         5|\n",
      "|[0.40784314274787...|         8|\n",
      "|[0.16470588743686...|         5|\n",
      "|[0.10196078568696...|         5|\n",
      "|[0.09019608050584...|         8|\n",
      "|[0.20000000298023...|         5|\n",
      "|[0.87450981140136...|         8|\n",
      "|[0.63137257099151...|         5|\n",
      "|[0.29803922772407...|        12|\n",
      "|[0.26666668057441...|         5|\n",
      "|[0.37647059559822...|         1|\n",
      "|[0.87843137979507...|         7|\n",
      "|[0.12941177189350...|         5|\n",
      "|[0.83137255907058...|        14|\n",
      "|[0.0,0.0,0.0,0.0,...|        14|\n",
      "|[0.10588235408067...|         5|\n",
      "|[0.85098040103912...|        14|\n",
      "|[0.56862747669219...|         5|\n",
      "|[0.92156863212585...|         5|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cluster calculation for new images\n",
    "prediction = model.transform(new_features)\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d1ea5b5-1f5d-45fc-9200-14be6f7952bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Stop!\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "\n",
    "print(\"Spark Session Stop!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780ee6a-b090-4f31-9725-a90fd538a7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
